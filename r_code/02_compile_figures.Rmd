---
title: "02_compile_figures"
author: "Bella Oleksy"
date: "created 12/22/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Source libraries & metadata
```{r setup, include=FALSE}


library(here)
# root.dir<-here()
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir='..')
# knitr::opts_knit$set(root.dir='root.dir')
knitr::opts_chunk$set(out.width = '50%',fig.height=10) 
# renv::snapshot()

source(here("r_code/scripts/librariesAndFunctions.R"))

#Read in metadata google sheet
# metadata<-read_sheet("https://docs..google.com/spreadsheets/d/1is87WT3n_TU76pTyiis3Os08JJiSmWc2G6K4bthJhU8/edit#gid=952562522") 
metadata<-read_csv(here("data/lakeMetadata_20221222.csv")) #time to switch to a static file

```


# Import data
##### Metabolism
```{r load raw metab & metadata, include=FALSE}
####PULL IN METABOLISM DATA######
source(here("r_code/scripts/dataPullMetab.R")) 

rm(cur)
rm(dontuse)
rm(MueggelseeZMix)
rm(bella_ER)


#and join

bella_metab_withMetaData <- left_join(bella_metab, metadata, by = c('lakeName'))



##EXTENDED SUMMER -- add a month on either end
# Trim to only "extended" dates. In the northern hemisphere this is May1-Oct1, and in the southern hemisphere this is Nov1-May1
bella_metab_withMetaData_extendedSummer<- bella_metab_withMetaData %>%
  filter(!lakeName=="YunYang") %>% #Exclude YYL because the shoulder seasons are actually the most productive here.
  select(solarDay, lakeName, GPP_mgCm2, GPP_mgCL, zMix, `Latitude (decimal degrees)`) %>%
  mutate(year=year(solarDay),
         DOY=yday(solarDay), 
         hemisphere = ifelse(`Latitude (decimal degrees)` < 0, #Assign northern or southern hemisphere
                        "southern", 
                        "northern")) %>% 
  mutate(summer_start = ifelse(hemisphere=="northern",
                        121, #May 1 - summer start n. hemisphere
                        305), #Nov 1 -  summer start s. hemisphere
         summer_end = ifelse(hemisphere=="northern",
                        274, #Oct 1 - summer end n. hemisphere
                        91)) #April 1- summer end s. hemisphere

#Divide into two dataframes by hemisphere, otherwise couldn't get case_when() to work 
bella_metab_withMetaData_northern_extendedSummer<- bella_metab_withMetaData_extendedSummer %>%
  filter(hemisphere=="northern")%>%
  filter(!lakeName=="YunYang") %>%
  mutate(season = case_when(hemisphere=="northern" & DOY > summer_start & DOY < summer_end ~ "summer",
                            T ~ "other"))  # specify when the "summer" season is in effect in either hemisphere


bella_metab_withMetaData_southern_extendedSummer<- bella_metab_withMetaData_extendedSummer %>%
  filter(hemisphere=="southern")%>%
  mutate(season = case_when(hemisphere=="southern" & DOY > summer_start | DOY < summer_end ~ "summer",
                            T ~ "other"))  # specify when the "summer" season is in effect in either hemisphere

bella_metab_withMetaData_extendedSummer <- bind_rows(bella_metab_withMetaData_northern_extendedSummer, bella_metab_withMetaData_southern_extendedSummer)

bella_metab_extendedSummer<-bella_metab_withMetaData_extendedSummer %>%
  filter(season=="summer") %>%
  select(1:5)

YYL<- bella_metab_withMetaData %>%
  filter(lakeName=="YunYang") %>%
  select(solarDay, lakeName, GPP_mgCm2, GPP_mgCL, zMix)

bella_metab_extendedSummer <- bind_rows(bella_metab_extendedSummer,YYL)


bella_metab_extendedSummer_withMetaData  <- bella_metab_extendedSummer %>%
  mutate(GPP_mgCm2 = na_if(GPP_mgCm2, GPP_mgCm2<1)) %>%
  left_join(., metadata, by = c('lakeName'))

bella_metab_summary <- bella_metab_extendedSummer %>%
  mutate(GPP_mgCm2 = na_if(GPP_mgCm2, GPP_mgCm2<1)) %>%
  group_by(lakeName) %>% 
  summarise(n=n(),
            n_NAs=sum(is.na(GPP_mgCm2)),
            meanGPP= mean(GPP_mgCm2, na.rm = T) , 
            medianGPP = median(GPP_mgCm2, na.rm= T),
            meanzMix=mean(zMix, na.rm=T),
            medianzMix=median(zMix, na.rm=T),
            meanGPP_vol=mean(GPP_mgCL, na.rm=T),
            medianGPP_vol=median(GPP_mgCL, na.rm=T),
            sdGPP= sd(GPP_mgCm2, na.rm = T)) %>% 
  mutate(seGPP=sdGPP/sqrt(n),
         GPP5=meanGPP+qnorm(0.05)*seGPP,
         GPP25=meanGPP+qnorm(0.25)*seGPP,
         GPP50=meanGPP+qnorm(0.5)*seGPP,
         GPP75=meanGPP+qnorm(0.75)*seGPP,
         GPP95=meanGPP+qnorm(0.95)*seGPP,
         perc_missing_days=(n_NAs/153)*100)%>% # calculate percentage of missing days. If > 50%, toss those lakes out
  filter(!perc_missing_days>50)

length(unique(bella_metab_extendedSummer$lakeName))


# rm(bella_metab_withMetaData_northern_extendedSummer,bella_metab_withMetaData_southern_extendedSummer,
#     # bella_metab_withMetaData,
#    bella_GPP, bella_metab, bella_zMix)
```

#### Loads
```{r pull in load estimates, include=FALSE}
#######PULL IN LOAD DATA########

source(here("r_code/scripts/dataPullLoads.R")) #Added on 2021-04-26; Erken added 2021-12-08


#Declutter Global Environment
rm(list = ls()[grep("mueggelsee", ls())])
rm(list = ls()[grep("_C_", ls())])
rm(list = ls()[grep("_Q_", ls())])
rm(list = ls()[grep("Taupo_", ls())])
rm(list = ls()[grep("loch_", ls())])
rm(list = ls()[grep("zwart_", ls())])
rm(list = ls()[grep("lm", ls())])
rm(list = ls()[grep("Loch", ls())])
rm(list = ls()[grep("erken", ls())])
rm(list = ls()[grep("acton", ls())])
rm(dontuse,  cur)
# rm(load_estimates_huisman_C, load_estimates_huisman_P)


#All of the MEASURED inflows
glimpse(inflow_conc_summary)

inflow_conc_summary_metab<-inflow_conc_summary %>%
  select(lakeName, contains("DOC"), contains("TP"),dataset) %>%
  # select(-TN_load_kg_total, -TN_load_kgday_mean) %>%
  left_join(.,bella_metab_summary %>%
                  select(lakeName, n, meanGPP, medianGPP,
                         meanGPP_vol, medianGPP_vol,
                         meanzMix, medianzMix),
             by="lakeName") %>%
  rename(DOC_load_kg=DOC_load,
         TP_load_kg=TP_load) %>%
    mutate(DOC_load_kgday_mean=DOC_load_kg/n,
         TP_load_kgday_mean=TP_load_kg/n)


#ALl of the MODELED inflows
glimpse(modelled_loads_kg)


#Pull out only the lakes WITHOUT measurements/gauged inflows
modelled_loads_kg_norepeat<-anti_join(modelled_loads_kg,inflow_conc_summary, by="lakeName") %>%
  left_join(.,bella_metab_summary %>%
                  select(lakeName, n, meanGPP, medianGPP,
                         meanGPP_vol, medianGPP_vol,
                         meanzMix, medianzMix),
             by="lakeName") %>%
  filter(!lakeName=="Rotoiti") %>%
  mutate(DOC_load_kgday_mean=DOC_load_kg/n,
         TP_load_kgday_mean=TP_load_kg/n) %>%
  select(-V, -HRT_days, -Qin)

# loads_master<-left_join(load_comparisons_wide,bella_metab_summary %>%
#                   select(lakeName, n, meanGPP, medianGPP,
#                          meanzMix, medianzMix),
#              by="lakeName") %>%
#   filter(!lakeName=="Rotoiti") %>% #Exclude Rotoiti, high number of missing days
  # mutate(DOC_load_kgday_mean=DOC_load_kg/n,
  #        TP_load_kgday_mean=TP_load_kg/n)



loads_master<-full_join(inflow_conc_summary_metab,modelled_loads_kg_norepeat,
                        by=c("lakeName","meanGPP","medianGPP",
                             "meanGPP_vol", "medianGPP_vol",
                             "DOC_load_kg","TP_load_kg",
                             "DOC_gm3","TP_mgm3",
                             "DOC_load_kgday_mean","TP_load_kgday_mean","n",
                             "meanzMix","medianzMix",
                             "dataset")) 
  # select(-DOC_TP_massmass_total) 
  # left_join(.,metadata %>%
  #             select(lakeName, `Lake residence time (year)`, `Surface area (ha)`,
  #                    `Maximum lake depth (m)`, `Volume (m3)`)) %>%
  # rename(HRT_days=`Lake residence time (year)`,
  #        SA_ha=`Surface area (ha)`,
  #        zMax=`Maximum lake depth (m)`,
  #        V_m3=`Volume (m3)`) %>%
  # mutate(HRT_days=HRT_days*365)

glimpse(loads_master)

#### MASTER DF! ###
master_df<-left_join(bella_metab_summary %>%
                  select(lakeName, n, meanGPP, medianGPP,
                         meanGPP_vol, medianGPP_vol),
                loads_master, by=c("lakeName","n","medianGPP","meanGPP",
                                   "meanGPP_vol", "medianGPP_vol"))


```

#### Lake nutrients
```{r lake nutrient data, include=FALSE}


source(here("r_code/scripts/dataPullNutrients.R"))
rm(list = ls()[grep("nuts", ls())])
rm(list = ls()[grep("UNDERC", ls())])
rm(WATER_CHEM, solomonLakeData, solomonLakeData_trim, dataA, dataB, catchment_newtz)

#Merge with master_df
glimpse(master_df)
glimpse(newts_full)

 master_df<- left_join(master_df, newts_full %>%
                                    select(lakeName, TP_ugL, TN_ugL, DOC_mgL,
                                           abs440, abs250, abs280, abs254, chla_ugL),
                      by="lakeName") %>%
    left_join(.,metadata %>%
              select(lakeName, `Lake residence time (year)`, `Surface area (ha)`,
                     `Maximum lake depth (m)`,`Mean lake depth (m)`,  `Volume (m3)`, `watershed area (km2)`, `Surface area (km2)`)) %>%
  rename(HRT_days=`Lake residence time (year)`,
         SA_ha=`Surface area (ha)`,
         zMax=`Maximum lake depth (m)`,
         zMean=`Mean lake depth (m)`,
         V_m3=`Volume (m3)`,
         SA_km2=`Surface area (km2)`,
         WSA_km2=`watershed area (km2)`) %>%
  mutate(HRT_days=HRT_days*365,
         WALA=(WSA_km2-SA_km2)/(SA_km2))%>%
  distinct() #remove duplicate rows
```


#### Hydrological classification
```{r}
glimpse(master_df)
master_df <- master_df %>%
  mutate(HRT_sizeclass=
           ifelse(HRT_days >0 & HRT_days <=10, "< 10", 
                  ifelse(HRT_days >10 & HRT_days <=100, "10-100", 
                         ifelse(HRT_days >100 & HRT_days <=1000, "100-1000", 
                                ifelse(HRT_days >1000 & HRT_days <=10000, "1000-10,000",
                                       ifelse(HRT_days >10000 , ">10,000", "error")))))) %>%
  mutate(HRT_sizeclass = factor(HRT_sizeclass,
                                levels = c("< 10", "10-100", "100-1000",
                                           "1000-10,000",">10,000"))) #Reorder factors for plotting
master_df<-master_df %>%
  mutate(LSA_km2=SA_ha/100,
         LSA_sizeclass=
           ifelse(LSA_km2 >0 & LSA_km2 <=0.1, "< 0.1", 
                  ifelse(LSA_km2 >0.1 & LSA_km2 <=1, "0.1-1", 
                         ifelse(LSA_km2 >1 & LSA_km2 <=10, "1-10", 
                                ifelse(LSA_km2 >10 & LSA_km2 <=100, "10-100",
                                       ifelse(LSA_km2 >100 , ">100", "error")))))) %>%
  mutate(LSA_sizeclass = factor(LSA_sizeclass,
                             levels = c("< 0.1", "0.1-1", "1-10",
                                        "10-100",">100"))) #Reorder factors for plotting


master_df<-master_df%>%
  mutate(LSA_sizeclass_quantile=cut_number(LSA_km2, 5, dig.lab=1),
         Lake_maxdepthclass_quantile=cut_number(zMax,5, dig.lab=1),
         Lake_meandepthclass_quantile=cut_number(zMean,5, dig.lab=1),
         ) #Another LSA category type that
#uses evenly spaced quantiles for binning observations. 

#Visualize lake size classes
master_df %>%
  group_by(LSA_sizeclass) %>%
  summarize(n=n()) %>%
  ggplot(aes(x=LSA_sizeclass, y=n, fill=LSA_sizeclass))+
  geom_bar(stat="identity",  color="black")+
  geom_text(aes(label=n), vjust=-1) +
  theme_pubr(base_size = 18)+
  scale_fill_manual(values=c("#003049","#d62828","#f77f00","#fcbf49","#eae2b7"),
                    name="Size class")+
  xlab("Lake surface area size class (km2)")+
  ylab("Count")+
  ylim(c(0,30)) +
  ggtitle("Lake size classes - unequal distribution") 

#Visualize lake HRT classes
master_df %>%
  group_by(HRT_sizeclass) %>%
  summarize(n=n()) %>%
  ggplot(aes(x=HRT_sizeclass, y=n, fill=HRT_sizeclass))+
  geom_bar(stat="identity",  color="black")+
  geom_text(aes(label=n), vjust=-1) +
  theme_pubr(base_size = 18)+
  scale_fill_manual(values=c("#003049","#d62828","#f77f00","#fcbf49","#eae2b7"),
                    name="HRT class")+
  xlab("Lake HRT class (days)")+
  ylab("Count")+
  ylim(c(0,30)) +
  ggtitle("Lake HRT classes - unequal distribution") 

```

#Potential figures

### Figure 2. Pred vs Obs params for 18 calibration lakes

```{r}

predVals<-read.csv(here("data/preliminaryMetropolisResults/ExtendedRangeParameter_outputWobservedloads.csv")) 
obsVals<-read.csv(here("data/preliminaryMetropolisResults/gridSearchInput_wphyto4bella.csv")) 
compareVals<-left_join(predVals,obsVals %>% select(lakeName, TP, DOC, meanzMix, medianGPP, meanGPP))

A <- compareVals %>%
  ggplot(aes(y=TPHat, x=TP))+
  geom_point(alpha=0.7, size=2.5)+
  theme_few()+
  geom_abline(intercept=0, slope=1)+
  scale_y_continuous(trans = log10_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Modeled lake TP (mg m'^-3,')')))+
  scale_x_continuous(trans = log10_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Mean lake TP (mg m'^-3,')')))


B  <- compareVals %>%
  ggplot(aes(y=CHat, x=DOC))+
  geom_point(alpha=0.7, size=2.5)+
  theme_few()+
  geom_abline(intercept=0, slope=1)+
  scale_y_continuous(trans = log10_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Modeled lake DOC (g m'^-3,')')))+
  scale_x_continuous(trans = log10_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Mean lake DOC (g m'^-3,')')))

C  <- compareVals %>%
  ggplot(aes(y=zMixHat, x=meanzMix))+
  geom_point(alpha=0.7, size=2.5)+
  theme_few()+
  geom_abline(intercept=0, slope=1)+
  scale_y_continuous(trans = log10_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Modeled z'[mix],' (m)')))+
  scale_x_continuous(trans = log10_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Mean z'[mix],' (m)')))

D  <-
  compareVals %>%
  ggplot(aes(y=GPPHat, x=meanGPP))+
  geom_point(alpha=0.7, size=2.5)+
  theme_few()+
  geom_abline(intercept=0, slope=1)+
  scale_y_continuous(trans = log2_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Modeled GPP (mg C m'^-2,' day'^-1,')')))+
  scale_x_continuous(trans = log2_trans(),
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x)),
    name = expression(paste('Mean GPP (mg C m'^-2,' day'^-1,')')))

(A+B)/(C+D) + plot_annotation(tag_levels = 'A')

ggsave(here("figures/modeled_vs_measured_TP_DOC_zMIX_GPP_18lakes.png"), dpi=600, width=8,height=8, units="in")


```

### Figure 4. Parameters

Create the skeleton for an eventual figure that shows the updated parameters and ranges
```{r}
lit_params <- read.csv("~/Google Drive/My Drive/Collaborations/(1) Kelly Model Test/Data/Data repository/ParameterEstimatesLiterature.csv") %>%
  select(-description, -sources) %>%
  mutate(set="kelly") %>% #call this kelly for now so we have the kelly values map onto the literature range
         # value=(min+max)/2) %>%
  rename(min_lit=min,
         max_lit=max)
  # pivot_longer(2:3)


#First calculate the 95% confidence intervals from the Metroplis "wide range"
gridSearchVals<-read.csv(here("data/preliminaryMetropolisResults/goodChainBI_wideRange_longCRCrun.csv"),
                 stringsAsFactors = FALSE) 

#Quick ftns for getting 10th and 90th quantiles.
#Tried 5 and 95th but there are some extreme outliers that made the plots look weird
quant_10 <- function(x)  {
  quantile(x, probs = 0.10)
}

quant_90 <- function(x)  {
  quantile(x, probs = 0.90)
}



#Summarize 10th and 90th quantile for each parameter
gridSearchQuantiles <-
  gridSearchVals %>%
  summarise_all(list(quant_90=~quant_90(.), quant_10=~quant_10(.))) %>%
  pivot_longer(cols=everything(),
               names_prefix = c("_quant_95","_quant_5"),
               names_sep = "_quant_",
               names_to = c("parameter","quantile")) %>% 
  pivot_wider(id_cols=parameter,
              names_from=quantile,
              values_from=value) %>%
  rename(quant_90=`90`,
         quant_10=`10`) %>%
  mutate(quant_90=exp(quant_90), #exponentiate since values were on log scale
         quant_10=exp(quant_10))

params<-read.csv(here("data/preliminaryMetropolisResults/kellymodel_parametersets4bella.csv"),
                 stringsAsFactors = FALSE) %>%
  rename(set=X)

#Grab just the maximum log likelihood from the 'wide range' Metropolis run
paramSetLong <- params %>%
  # filter(set=="max log likelihood wide") %>%
  # select(-set) %>%
  pivot_longer(pA:rec, names_to="parameter", values_to="value") 

kellySet <- paramSetLong %>%
  filter(set=="kelly")

maxLikelihoodSet <- paramSetLong %>%
  filter(set=="max log likelihood wide") %>%
  rename(max_likelihood=value) %>%
  mutate(set="optim")
  # mutate(max_likelihood=exp(max_likelihood)) # exponentiate since values were on log-scale


#Join with the 5th and 95th quantile dataframe
optim_params <- full_join(gridSearchQuantiles,maxLikelihoodSet)

# Parameter comparison plots (optim vs. kelly + literature range)
optim_params %>%
  pivot_longer(cols=max_likelihood, names_to="name", values_to="value") %>%
  select(-name) %>%
  bind_rows(., kellySet) %>%
  left_join(., lit_params) %>%
  ggplot(aes(x=set, y=value, group=set, color=set)) + 
  geom_point()+
  geom_errorbar(aes(ymin=min_lit, ymax=max_lit), width=.2,
                 position=position_dodge(.9)) +
  # geom_pointrange(aes(ymin=min_lit, ymax=max_lit)) +
  geom_errorbar(aes(ymin=quant_10, ymax=quant_90), width=.2,
                 position=position_dodge(.9)) +
  scale_color_manual(values=c("black","purple"))+
  facet_wrap(~parameter, scales="free", ncol=5) +
  theme_few()+
  theme(legend.position="none")
ggsave(here("figures/point_plots_kelly_optim_lit_parameter_ranges.png"), dpi=600, width=7,height=4.5, units="in")


#Histograms of all the parameters
gridSearchVals %>%
  pivot_longer(cols=everything(), names_to = "parameter", values_to = "value") %>%
  ggplot(aes(x=exp(value)))+
  geom_histogram(bins=50)+
  geom_vline(aes(xintercept=max_likelihood, group=parameter), optim_params, color="maroon")+
  facet_wrap(~parameter, scales="free", ncol=5) +
  theme_few()+
  labs(title="Histograms of wide-range parameter set",
       subtitle="Red line indicates maximum log likelihood values")+
  theme(axis.title.x=element_blank())
ggsave(here("figures/histograms_parameter_maxlogliklihood.png"), dpi=600, width=14,height=8, units="in")


#

# 
# params<-data.frame(c(kDOC=0.42,kA=0.00022,lA=0.1,pA=1.2,hA=55,mA=2,decay=0.001,cA=0.015,v=0.1,rec=0.95))%>%
#   rownames_to_column()
# colnames(params) <- c('parameter','value')
# params$cat <- "optim"
# 
# lit_params <- read.csv("~/Google Drive/My Drive/Collaborations/(1) Kelly Model Test/Data/Data repository/ParameterEstimatesLiterature.csv") %>%
#   select(-description, -sources) %>%
#   mutate(cat="range") %>%
#   pivot_longer(2:3)
# 
# table <- full_join(params, lit_params)
# 
# table %>%
#   ggplot(aes(x=cat, y=value, fill=cat, shape=cat)) +
#   geom_point(size=2.5)+
#   facet_wrap(~parameter, scales="free",nrow=2)+
#   theme_few()+
#   theme(legend.position="none", 
#         axis.title.x=element_blank())+
#   scale_fill_manual(values=c("red","black"))+
#   scale_shape_manual(values=c(21,22)) +
#   geom_line(aes(group=cat), linetype=1)

params %>%
  pivot_longer(-1) %>%
  ggplot(aes(x=set, y=value, fill=set, shape=set)) +
  geom_point(size=2.5)+
  facet_wrap(~name, scales="free",nrow=2)+
  theme_few()+
  theme(legend.position="none", 
        axis.title.x=element_blank())+
  scale_fill_manual(values=c("red","black","purple"))+
  scale_shape_manual(values=c(21,22,25)) 
  # geom_line(aes(group=cat), linetype=1)

```


### Table 1 - lake metadata
```{r}

#morphometry and nutrient dataframe
morphNut<-master_df%>%
  select(lakeName, SA_ha, HRT_days, V_m3, zMean, DOC_mgL, TP_ugL, DOC_load_kg, TP_load_kg) %>%
  mutate(CP=DOC_load_kg/(TP_load_kg*1000),
         volume_1000m3=V_m3/1000)%>%
  select(-V_m3) %>%
  left_join(.,metadata %>%
                select(lakeName, `Latitude (decimal degrees)`, `Longitude (decimal degrees)`)) %>%
  mutate(across(where(is.numeric), round, 2)) #round all numeric values to 2 decimal places
str(morphNut)
#metab dataframe
metab<-bella_metab_withMetaData_extendedSummer %>%
  group_by(lakeName)%>%
  skim()%>%
  filter(skim_type=="numeric") %>%
  filter(skim_variable %in% c("GPP_mgCm2", "zMix")) %>%
  select(skim_variable, lakeName, numeric.mean, numeric.sd) %>%
  # mutate(
  #   numeric.mean=round(numeric.mean,0),
  #   numeric.sd=round(numeric.sd,1),
  #   meansd = paste0(numeric.mean, " (",numeric.sd,")")) %>%
  # select(-numeric.mean,-numeric.sd) %>%
    mutate(
    numeric.mean=round(numeric.mean,0)) %>%
  select(-numeric.sd) %>%
  pivot_wider(names_from = "skim_variable", values_from = "numeric.mean")


###EXPORT TABLE
summary_table_export <- 
  right_join(morphNut, metab, by="lakeName")%>%
  hux() %>% 
  arrange(lakeName) %>%
  relocate(`Latitude (decimal degrees)`, .after = lakeName) %>% #rearranging in case this presents a problem in modeling
  relocate(`Longitude (decimal degrees)`, .after = `Latitude (decimal degrees)`)%>%
  rename(`Lake name`=lakeName,
         `SA (ha)`=SA_ha,
         `HRT (days)`=HRT_days,
         `V (1000 m3)`=volume_1000m3,
         `Mean depth (m)`=zMean,
         `DOC (mg/L)`=DOC_mgL,
         `TP (ug/L)`= TP_ugL,
         `DOC load (kg)`=DOC_load_kg,
         `TP load (kg)`=TP_load_kg,
         `Inflow C:P`=CP,
         `GPP (mg C m2 day)`=GPP_mgCm2,
         `Mixed layer depth (m)`=zMix)%>%
  add_colnames() %>%
  add_footnote("SA = lake surface area; HRT = hydrologic residence time; V = lake volume; 
               DOC = mixed layer dissolved organic carbon concentration; TP = mixed layer total phosphorus concentration;
               GPP = gross primary production") %>%
  set_bold(row = 1, col = everywhere, value = TRUE) %>% 
  set_all_borders(TRUE) %>%
    set_all_padding(0) %>%
  set_outer_padding(0) %>%
  theme_article()
# 
# summary_table_export<-summary_table_export %>%
#   set_all_padding(0) %>%
#   set_outer_padding(0) 

quick_docx(summary_table_export, file = 'results/draft MS figs/tables/Table1.docx')


library(flextable)
library(officer)
ft <- as_flextable(summary_table_export) 

summary_table_export<-regulartable(summary_table_export) %>% 
  padding(padding = 0, part = "all") %>% 
  autofit() %>% 
  # dim_pretty() %>%
  # width(c(0.6797418,  1.8088650 , 1.9363539,  0.6797418,  0.7808974 , 1.0196126 ,
  #         1.0783963 , 0.8233439 , 0.6367730 , 1.1470269 , 0.9770915 , 0.6962280 , 1.3752984 ,
  #         1.4773492)) %>%
  print(preview = "docx")

# sect_properties <- prop_section(
#   page_size = page_size(orient = "landscape",
#     width = 8.3, height = 11.7),
#   type = "continuous",
#   page_margins = page_mar(),
#   section_columns = section_columns(widths = c(4.75, 4.75))
# )
save_as_docx(summary_table_export, pr_section = sect_properties,
             path = 'results/draft MS figs/tables/Table1_testing.docx')


```


### Fig2- lake and stream nutrients
```{r}
FigX_lake_and_load_conc<-master_df %>%
  ggplot(aes(x=DOC_mgL, y=TP_ugL,
             # fill=DOC_mgL/(TP_ugL),
             ))+
  geom_point(shape=21, size=3, color="black", fill="grey50")+
  # geom_abline(intercept = 0, slope = 1)+
  ylab(expression('Mean lake TP ug L'^-1))+
  xlab(expression(paste('Mean lake DOC mg L'^-1,)))+
  # scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
  #                                  name="Lake DOC:TP\n(mass:mass)")+
  theme_classic()+
    theme(legend.position = c(0.02, 0.89),
        legend.justification = c("left", "bottom"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "horizontal",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0),
        legend.title = element_text(size=10))+

master_df %>%
  filter(!dataset=="NA")%>%
  ggplot(aes(x=log10(DOC_load_kg), y=log10(TP_load_kg),
             # fill=DOC_load_kgday_mean/(TP_load_kgday_mean*1000),
             shape=dataset))+
  geom_point( size=3, color="black", fill="grey20")+
  scale_shape_manual(values=c(21,25),
                     name="Inflow estimates:")+
  # geom_abline(intercept = 0, slope = 1)+
  ylab(expression('Mean TP load kg day'^-1))+
  xlab(expression(paste('Mean DOC load kg day'^-1,)))+
  # scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
  #                                  name="Load DOC:TP\n(mass:mass)")+
  # annotate(geom="text",x=0.0001, y=150, label="n=17",
  #             color="black")+
  theme_classic()+
    geom_text_repel(aes(label = lakeName), size = 3)+
  #Moves legend to inside of plot
  theme(legend.position = c(0.05, 0.79),
        legend.justification = c("left", "bottom"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "vertical",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0),
        legend.title = element_text(size=10)) +
 plot_annotation(tag_levels = 'A')

FigX_lake_and_load_conc
ggsave(here("results/draft MS figs/lakeAndLoadConcentrations.png"), width=10, height=5,units="in", dpi=600)



```

##### SIL nutrient & load figs
```{r}


  my_labeller <- as_labeller(c(
                             DOC_mgL="log[10]~DOC~(mg~L^1)", TP_ugL="log[10]~TP~(mu~g~L^-1)"),
                             
                           default = label_parsed)

A<-master_df %>%
  select(lakeName,DOC_mgL,TP_ugL) %>%
  pivot_longer(-1) %>%
  ggplot()+
  geom_density(aes(x = log10(value)),fill="#5E813F") +
  geom_rug(aes(x = log10(value), y = 0), sides="b") +
  facet_wrap(.~name, scales="free",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  theme_pubr(base_size = 16)+
  theme(legend.position="none",
        axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )
ggsave(here("figures/SIL/TP_DOC_distributions.png"), width=7, height=1.5,units="in", dpi=600)



B<-master_df %>%
  ggplot(aes(y=DOC_mgL, x=TP_ugL,
             # fill=DOC_mgL/(TP_ugL),
             ))+
  geom_point(shape=21, size=3, color="black", fill="grey50", alpha=0.5)+
  geom_abline(intercept = 0, slope = 1, linetype="dashed")+
  xlab(expression('Mean lake TP ug L'^-1))+
  ylab(expression(paste('Mean lake DOC mg L'^-1,)))+
  # geom_text_repel(aes(label = lakeName),box.padding = 0.5, max.overlaps = 2) +
  theme_pubr()+
    theme(legend.position = c(0.02, 0.89),
        legend.justification = c("left", "bottom"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "horizontal",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0),
        legend.title = element_text(size=10))
ggsave(here("figures/SIL/TPvsDOC_label_outliers.png"), width=7, height=5,units="in", dpi=600)


(A/B)+plot_layout(heights = c(0.2,1))
ggsave(here("figures/SIL/TPvsDOC_density.png"), width=9, height=7,units="in", dpi=600)


master_df %>%
  filter(!dataset=="NA")%>%
  ggplot(aes(y=DOC_load_kg, x=TP_load_kg, fill=log10(SA_ha)))+
  geom_point(shape=21, size=3, color="black",  alpha=0.5)+
  geom_abline(intercept = 0, slope = 1, linetype="dashed")+
  xlab(expression('Mean TP load kg day'^-1))+
  ylab(expression(paste('Mean DOC load kg day'^-1,)))+
  scale_x_log10(labels = scales::comma)+
  scale_y_log10(labels = scales::comma)+
  theme_pubr()+
  scale_fill_gradient(name="log10 surface area (ha)",
                      low = "darkblue", high = "red")+
  # geom_text_repel(aes(label = lakeName),box.padding = 0.5, max.overlaps = 2) +
  #Moves legend to inside of plot
  theme(legend.position = c(0.05, 0.65),
        legend.justification = c("left", "bottom"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "vertical",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0),
        legend.title = element_text(size=10))
ggsave(here("figures/SIL/TPvsDOC_loads.png"), width=7, height=5,units="in", dpi=600)


```


#### Supp Fig- transformations C:P
```{r}
#Paired points -- how does Stream C:P compare to Lake C:P?

#DOC
pairedDF1<- master_df %>%
  filter(!lakeName=="LittleRock")%>%
  select(lakeName, DOC_gm3, DOC_mgL) %>%
  drop_na() %>%
  mutate(cat="DOC")
  
ggpaired(pairedDF1, cond1 = "DOC_gm3", cond2 = "DOC_mgL", line.color = "gray", line.size = 0.4,
         fill = "condition", palette = "jco")


#TP
pairedDF2<- master_df %>%
  filter(!lakeName=="LittleRock")%>%
  select(lakeName,  TP_mgm3, TP_ugL) %>%
  drop_na() %>%
  mutate(cat="TP")
  
ggpaired(pairedDF2, cond1 = "TP_mgm3", cond2 = "TP_ugL", line.color = "gray", line.size = 0.4,
         fill = "condition", palette = "jco")

#Stoich
pairedDF<- master_df %>%
  filter(!lakeName=="LittleRock")%>%
  mutate(loadCP=(DOC_gm3/(TP_mgm3)),
         lakeCP=(DOC_mgL/TP_ugL))  %>%
  select(lakeName,dataset, loadCP, lakeCP) 

ggpaired(pairedDF, cond1 = "loadCP", cond2 = "lakeCP", line.color = "gray50", line.size = 0.4,
         fill = "condition", palette = "jco")


#logStoch
pairedDF3<- master_df %>%
  filter(!lakeName=="LittleRock")%>%
  mutate(loadCP=log(DOC_gm3/(TP_mgm3)),
         lakeCP=log(DOC_mgL/TP_ugL))  %>%
  select(lakeName, loadCP, lakeCP) %>%
  mutate(cat="stoich")

ggpaired(pairedDF3, cond1 = "loadCP", cond2 = "lakeCP", line.color = "gray50", line.size = 0.4,
         fill = "condition", palette = "jco")


#All params
pairedDF1<- pairedDF1 %>%
  rename(inflow=DOC_gm3,
         lake=DOC_mgL)
pairedDF2<- pairedDF2 %>%
  rename(inflow=TP_mgm3,
         lake=TP_ugL)
pairedDF3<- pairedDF3 %>%
  rename(inflow=loadCP,
         lake=lakeCP)
allPaired<-bind_rows(pairedDF1,pairedDF2,pairedDF3) %>%
  mutate(cat=factor(cat,
                    levels=c("DOC","TP","stoich")))



ggpaired(allPaired, cond1 = "inflow", cond2 = "lake", line.color = "gray50", line.size = 0.4,
         fill = "condition", palette = "jco") +
  facet_wrap(.~cat, scales="free_y")

# ggsave(here("results/draft MS figs/SuppFig.PairedPoints_C_P_CP.png"), width=9, height=8,units="in", dpi=600)


#Is there even a relationship between load C:P and lake C:P? 
cor.test(pairedDF3$inflow, pairedDF3$lake)

#Ugh, but across lakes, load and lake C:P are highly correlated. 
pairedDF3 %>%
  ggplot(aes(x=lake, y=inflow))+
  geom_point(shape=21,size=3, fill="grey50")

#Unless you don't log transform, but you should. 
master_df %>%
    mutate(loadCP=(DOC_gm3/(TP_mgm3)),
         lakeCP=(DOC_mgL/TP_ugL))  %>% 
    ggplot(aes(x=lakeCP, y=loadCP))+
  geom_point(shape=21,size=3, fill="grey50")
```

### Fig3- correleations among GPP, loads,zmix,nutrients,SA,volume
```{r}

  my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", LSA_km2="log[10]~Surface~Area~(km^2)",
                             meanzMix="log[10]~Mixed~layer~depth~(m)", V_m3="log[10]~Volume~(m^3)",
                             DOC_mgL="DOC~(mg~L^1)", TP_ugL="TP~(mu~g~L^-1)",
                             DOC_load_kgday_mean="Mean~daily~DOC~load~(kg)",
                             TP_load_kgday_mean="Mean~daily~TP~load~(kg)",
                             CP="DOC~to~TP~ratio~(loads)"),
                             
                           default = label_parsed)

GPP_correlations<-master_df %>%
  select(meanGPP, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean)) %>%
  pivot_longer(-(1)) %>%
  mutate(name=factor(name,
                     levels=c("DOC_load_kgday_mean","DOC_mgL",
                              "TP_load_kgday_mean","TP_ugL",
                              "CP","meanzMix",
                              "LSA_km2","V_m3")))%>%
  ggplot(aes(x=value, y=meanGPP))+
  geom_point(size=3, shape=21, color="black", fill="black", alpha=0.5)+
  facet_wrap(.~name, scales="free",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  scale_y_log10(expression(paste('GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(legend.position="none",
        axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") 
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )

GPP_correlations  


master_df %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  ggplot(aes(x=CP, y=meanGPP))+
  geom_point()+
  scale_y_log10(expression(paste('GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
    scale_x_log10("C:P",labels = scales::comma, breaks_log(n = 5, base = 10))


###For what it's worth, I tried segmented regression but nothing comes up. 
# segmented<-master_df %>%
#   mutate(CP=log10(DOC_load_kgday_mean/(TP_load_kgday_mean*1000)),
#         GPP= log10(meanGPP))
#   
# install.packages("segmented")  
# library(segmented)
# 
# my.lm<-lm(GPP~CP, segmented)
# 
# # have to provide estimates for breakpoints.
# # after looking a the data, 
# my.seg <- segmented(my.lm, 
#                     seg.Z = ~ CP, 
#                     psi = NA)
# 
# # When not providing estimates for the breakpoints "psi = NA" can be used.
# # The number of breakpoints that will show up is not defined
# #my.seg <- segmented(my.lm, 
# #                    seg.Z = ~ DistanceMeters, 
# #                    psi = NA)
# 
# # display the summary
# summary(my.seg)  


#### Also try this with the PREDICTED GPP values. 
#Do we qualitatively see the patterns that we would expect? 

  my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", LSA_km2="log[10]~Surface~Area~(km^2)",
                             meanzMix="log[10]~Mixed~layer~depth~(m)", V_m3="log[10]~Volume~(m^3)",
                             DOC_mgL="DOC~(mg~L^1)", TP_ugL="TP~(mu~g~L^-1)",
                             DOC_load_kgday_mean="Mean~daily~DOC~load~(kg)",
                             TP_load_kgday_mean="Mean~daily~TP~load~(kg)",
                             CP="DOC~to~TP~ratio~(loads)"),
                             
                           default = label_parsed)

predGPP_correlations<-
  master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  dplyr::select(PPareal, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  pivot_longer(-(1)) %>%
  mutate(name=factor(name,
                     levels=c("DOC_load_kgday_mean","DOC_mgL",
                              "TP_load_kgday_mean","TP_ugL",
                              "CP","meanzMix",
                              "LSA_km2","V_m3")))%>%
  ggplot(aes(x=value, y=PPareal))+
  geom_point(size=3, shape=21, color="black", fill="black", alpha=0.5)+
  geom_smooth(method="lm", se=T, color="black")+
  facet_wrap(.~name, scales="free",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  scale_y_log10(expression(paste('Predicted GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(legend.position="none",
        axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") 
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )

predGPP_correlations  


#####Both on the same graph?
#### Also try this with the PREDICTED GPP values. 
#Do we qualitatively see the patterns that we would expect? 
my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", LSA_km2="log[10]~Surface~Area~(km^2)",
                             meanzMix="log[10]~Mixed~layer~depth~(m)", V_m3="log[10]~Volume~(m^3)",
                             DOC_mgL="DOC~(mg~L^1)", TP_ugL="TP~(mu~g~L^-1)",
                             DOC_load_kgday_mean="Mean~daily~DOC~load~(kg)",
                             TP_load_kgday_mean="Mean~daily~TP~load~(kg)",
                             CP="DOC~to~TP~ratio~(loads)"),
                             
                           default = label_parsed)


  plot_data<-  master_df %>%
    left_join(., sims %>%
                select(lakeName, eqDOC:nutrient.limit.d),  by="lakeName") %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  select(meanGPP, PPareal, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  pivot_longer(-(1:2)) %>%
  rename(predictor_variable=name,
         predictor_value=value)%>%
  mutate(predictor_variable=factor(predictor_variable,
                     levels=c("DOC_load_kgday_mean","DOC_mgL",
                              "TP_load_kgday_mean","TP_ugL",
                              "CP","meanzMix",
                              "LSA_km2","V_m3")))%>%
  pivot_longer(-(3:4)) %>%
  rename(response_variable=name,
         response_value=value)%>%
    filter(response_value>1)%>%
  mutate(response_variable=factor(response_variable,
                     labels=c("Measured GPP","Modeled GPP")))

predGPP_correlations<- plot_data %>%
  # filter(response_variable=="Modeled GPP")%>%
  ggplot(aes(x=predictor_value, y=response_value, fill=response_variable, linetype=response_variable))+
  geom_point(size=3, shape=21, color="black", alpha=0.5)+
  geom_smooth(method="lm", se=T, color="black")+
  facet_wrap(.~predictor_variable, scales="free",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  scale_y_log10(expression(paste('Predicted GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
  scale_fill_manual(values=c("#ffc300","#003566"),
                    name="Legend:")+
  scale_linetype_manual(values=c(1,6),
                    name="Legend:")+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") 
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )

predGPP_correlations  

ggsave(here("results/draft MS figs/correlationsWithGPP.png"), width=9, height=8,units="in", dpi=600)

#JUST OBSERVED VALUES
left_join(sims, master_df %>%
              select(lakeName, medianGPP, dataset), by="lakeName") %>%
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
    select(medianGPP, PPareal, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP, DOC, SA, V_m3) %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  pivot_longer(-(1:2)) %>%
    rename(predictor_variable=name,
         predictor_value=value)%>%
  mutate(predictor_variable=factor(predictor_variable,
                     levels=c("DOC_load_kgday_mean","DOC",
                              "TP_load_kgday_mean","TP",
                              "CP","meanzMix",
                              "SA","V_m3")))%>%
  ggplot(aes(x=predictor_value, y=medianGPP))+
  geom_point(size=3, shape=21, color="black", alpha=0.5)+
  geom_smooth(method="lm", se=T, color="black")+
  facet_wrap(.~predictor_variable, scales="free_x",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  scale_y_log10(expression(paste('Observed GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
  # scale_fill_manual(values=c("#ffc300","#003566"),
  #                   name="Legend:")+
  # scale_linetype_manual(values=c(1,6),
  #                   name="Legend:")+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") ) 
  
#JUST PREDICTED VALUES
left_join(sims, master_df %>%
              select(lakeName, medianGPP, dataset), by="lakeName") %>%
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
    select(medianGPP, PPareal, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP, DOC, SA, V_m3) %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  pivot_longer(-(1:2)) %>%
    rename(predictor_variable=name,
         predictor_value=value)%>%
  # mutate(predictor_variable=factor(predictor_variable,
  #                    levels=c("DOC_load_kgday_mean","DOC",
  #                             "TP_load_kgday_mean","TP",
  #                             "CP","meanzMix",
  #                             "SA","V_m3")))%>%
  ggplot(aes(x=predictor_value, y=PPareal))+
  geom_point(size=3, shape=21, color="black", alpha=0.5)+
  geom_smooth(method="lm", se=T, color="black")+
  facet_wrap(.~predictor_variable, scales="free_x",ncol=2,
             strip.position="bottom")+
  # scale_y_log10(expression(paste('Predicted GPP (mg C m'^-2,' day'^-1,')')),
  #               labels = scales::comma, breaks_log(n = 6, base = 10))+
  # scale_fill_manual(values=c("#ffc300","#003566"),
  #                   name="Legend:")+
  # scale_linetype_manual(values=c(1,6),
  #                   name="Legend:")+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") ) 

summary(sims)

left_join(sims, master_df %>%
              select(lakeName, medianGPP, dataset), by="lakeName") %>%
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
    select(medianGPP, PPareal, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP, DOC, SA, V_m3) %>%
  ggplot(aes(x=PPareal, y=medianGPP))+
  geom_point()
```

#### Linear models
```{r}
GPP_linearmodels<-
#Modeled GPP
bind_rows(master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  select(PPareal, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
  mutate(CPload=DOC_load_kgday_mean/(TP_load_kgday_mean*1000),
         CPlake=DOC_mgL/TP_ugL) %>%
  pivot_longer(-PPareal) %>%
  rename(predictor=name) %>%
  nest(data = -c(predictor)) %>%
  mutate(
    fit = map(data, ~lm(log10(PPareal) ~ log10(value), data = .x)),
    tidy_out = map(fit, tidy)
  ) %>%
  unnest(cols = tidy_out) %>%
  select(-fit, -data) %>%
  filter(term != "(Intercept)") %>%
  # filter(p.value<0.05) %>%
  mutate(dataset="modeled GPP"),

#Observed GPP
master_df %>%
  select(meanGPP, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
  mutate(CPload=DOC_load_kgday_mean/(TP_load_kgday_mean*1000),
         CPlake=DOC_mgL/TP_ugL) %>%
  pivot_longer(-meanGPP) %>%
  rename(predictor=name) %>%
  nest(data = -c(predictor)) %>%
  mutate(
    fit = map(data, ~lm(log10(meanGPP) ~ log10(value), data = .x)),
    tidy_out = map(fit, tidy)
  ) %>%
  unnest(cols = tidy_out) %>%
  select(-fit, -data) %>%
  filter(term != "(Intercept)") %>%
  # filter(p.value<0.05) %>%
  mutate(dataset="measured GPP"))

GPP_linearmodels


```

#### ~SIL figures
```{r}


####Both on the same graph
#### Also try this with the PREDICTED GPP values. 
#Do we qualitatively see the patterns that we would expect? 
#Why can't I recreate the data from before? 
my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", LSA_km2="log[10]~Surface~Area~(km^2)",
                             meanzMix="log[10]~Mixed~layer~depth~(m)", V_m3="log[10]~Volume~(m^3)",
                             DOC_mgL="DOC~(mg~L^1)", TP_ugL="TP~(mu~g~L^-1)",
                             DOC_load_kgday_mean="Mean~daily~DOC~load~(kg)",
                             TP_load_kgday_mean="Mean~daily~TP~load~(kg)",
                             CP="DOC~to~TP~ratio~(loads)"),
                             
                           default = label_parsed)


  plot_data<-  master_df %>%
    left_join(., fits_kelly_long,  by="lakeName") %>%
    pivot_wider(names_from=name,values_from=value) %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  select(lakeName, meanGPP, GPPHat, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  pivot_longer(-(1:3)) %>%
  rename(predictor_variable=name,
         predictor_value=value)%>%
  mutate(predictor_variable=factor(predictor_variable,
                     levels=c("DOC_load_kgday_mean","DOC_mgL",
                              "TP_load_kgday_mean","TP_ugL",
                              "CP","meanzMix",
                              "LSA_km2","V_m3")))%>%
  pivot_longer(meanGPP:GPPHat) %>%
  rename(response_variable=name,
         response_value=value)%>%
  filter(response_value>1)%>%
  mutate(response_variable=factor(response_variable,
                     labels=c("Measured GPP","Modeled GPP")))

predGPP_correlations<- plot_data %>%
  # filter(response_variable=="Modeled GPP")%>%
  ggplot(aes(x=predictor_value, y=response_value, fill=response_variable, linetype=response_variable))+
  geom_point(size=3, shape=21, color="black", alpha=0.5)+
  geom_smooth(method="lm", se=T, color="black")+
  facet_wrap(.~predictor_variable, scales="free",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  scale_y_log10(expression(paste('Predicted GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
  scale_fill_manual(values=c("#ffc300","#003566"),
                    name="Legend:")+
  scale_linetype_manual(values=c(1,6),
                    name="Legend:")+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") 
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )

predGPP_correlations  
ggsave(here("figures/SIL/correlationsWithGPP.png"), width=9, height=8,units="in", dpi=600)



#Just measured values
  my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", LSA_km2="log[10]~Surface~Area~(km^2)",
                             meanzMix="log[10]~Mixed~layer~depth~(m)", V_m3="log[10]~Volume~(m^3)",
                             DOC_mgL="DOC~(mg~L^1)", TP_ugL="TP~(mu~g~L^-1)",
                             DOC_load_kgday_mean="Mean~daily~DOC~load~(kg)",
                             TP_load_kgday_mean="Mean~daily~TP~load~(kg)",
                             CP="DOC~to~TP~ratio~(loads)"),
                             
                           default = label_parsed)

predGPP_correlations<- plot_data %>%
  filter(response_variable=="Measured GPP")%>%
  ggplot(aes(x=predictor_value, y=response_value, fill=response_variable, linetype=response_variable))+
  geom_point(size=3, shape=21, color="black", alpha=0.5)+
  geom_smooth(method="lm", se=T, color="black")+
  facet_wrap(.~predictor_variable, scales="free",ncol=2,
             labeller=my_labeller, strip.position="bottom")+
  scale_y_log10(expression(paste('Measured or predicted GPP (mg C m'^-2,' day'^-1,')')),
                labels = scales::comma, breaks_log(n = 6, base = 10))+
  scale_fill_manual(values=c("#ffc300","#003566"),
                    name="Legend:")+
  scale_linetype_manual(values=c(1,6),
                    name="Legend:")+
  scale_x_log10("SA (ha)",labels = scales::comma, breaks_log(n = 5, base = 10))+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        plot.margin = margin(1,1,0.5,0.5, "cm") 
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )

predGPP_correlations  

ggsave(here("figures/SIL/correlationsWithGPP_measured_only.png"), width=9, height=8,units="in", dpi=600)

```

#### PCA?
```{r}


pca_data<-master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  filter(!lakeName %in% c("Kentucky"))%>% #extreme outlier with surface area, so dropping this for the sake of the analysis right now. 
  select(lakeName, DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
    mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  drop_na()

pca_data_withPPareal<-master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  filter(!lakeName %in% c("Kentucky"))%>% #extreme outlier with surface area, so dropping this for the sake of the analysis right now. 
  select(lakeName, PPareal,DOC_load_kgday_mean, TP_load_kgday_mean,
         meanzMix, TP_ugL, DOC_mgL, LSA_km2, V_m3) %>%
    mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean*1000)) %>%
  drop_na()


pca_fit<-pca_data %>%
  drop_na()%>%
  select(where(is.numeric)) %>% # retain only numeric columns
  scale() %>%                   # scale to zero mean and unit variance
  prcomp()                      # do PCA


pca_fit %>%
  # add PCs to the original dataset
  augment(pca_data_withPPareal) %>%
  ggplot(aes(.fittedPC1, .fittedPC2)) +
  geom_point(size=3, shape=21, aes(fill = log10(PPareal)))+
  geom_text_repel(aes(label = lakeName), size = 3)+
    scale_fill_continuous_sequential(palette = "Terrain", rev=TRUE)


pca_fit %>%
  # add PCs to the original dataset
  augment(pca_data_withPPareal) %>%
  ggplot(aes(PPareal, .fittedPC1)) +
  geom_point(size=3, shape=21, aes(fill = log10(PPareal)))+
  geom_text_repel(aes(label = lakeName), size = 3)+
  scale_fill_continuous_sequential(palette = "Terrain", rev=TRUE)

pca_fit %>%
  # add PCs to the original dataset
  augment(pca_data_withPPareal) %>%
  ggplot(aes(PPareal, .fittedPC2)) +
  geom_point(size=3, shape=21, aes(fill = log10(PPareal)))+
  geom_text_repel(aes(label = lakeName), size = 3)+
  scale_fill_continuous_sequential(palette = "Terrain", rev=TRUE)

pca_fit %>%
  # add PCs to the original dataset
  augment(pca_data_withPPareal) %>%
  ggplot(aes(PPareal, .fittedPC3)) +
  geom_point(size=3, shape=21, aes(fill = log10(PPareal)))+
  geom_text_repel(aes(label = lakeName), size = 3)+
  scale_fill_continuous_sequential(palette = "Terrain", rev=TRUE)


#########################
#Plot the rotation matrix
#########################
arrow_style <- arrow(
  angle = 20, length = grid::unit(8, "pt"),
  ends = "first", type = "closed"
)
pca_fit %>%
  tidy(matrix = "rotation") %>%
  pivot_wider(
    names_from = "PC", values_from = "value",
    names_prefix = "PC"
  ) %>%

  ggplot(aes(PC1, PC2)) +
  geom_segment(
    xend = 0, yend = 0,
    arrow = arrow_style
  ) +
  geom_text(aes(label = column), hjust = 1) +
  xlim(-0.6,0.6) + ylim(-0.5,0.7) +
  coord_fixed()


#########################
#Plot the variance explained
#########################

pca_fit %>%
  # extract eigenvalues
  tidy(matrix = "eigenvalues") %>%
  ggplot(aes(PC, percent)) + 
  geom_col() + 
  scale_x_continuous(
    # create one axis tick per PC
    breaks = 1:6
  ) +
  scale_y_continuous(
    name = "variance explained",
    # format y axis ticks as percent values
    label = scales::label_percent(accuracy = 1)
  )
```


### Fig4- GPP versus DOC
```{r}
MeanGPPvDOCvloadCP<-master_df %>%
  filter(!lakeName=="Annie")%>%
  mutate(CP=DOC_load_kgday_mean/(TP_load_kgday_mean)) %>%
  ggplot(aes(y=medianGPP, x=DOC_mgL, size=LSA_sizeclass, fill=CP))+
  geom_point(shape=21, color="black")+
  scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
                                   name="Load DOC:TP\n(mass:mass)")+
    scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
  theme_pubr(base_size = 18)+
  ylab(expression(paste('Median GPP (mg C m'^-2,' day'^-1,')')))+
  xlab(expression(paste('DOC (mg L'^-1,')')))+
      theme(legend.position = c(.90, 0.9),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0))+
    guides(size = guide_legend(label.position = "bottom", 
            title.position = "left", title.vjust = 0.8))

MeanGPPvDOCvlakeCP<-
  master_df %>%
  filter(!lakeName=="Annie")%>%
  ggplot(aes(y=medianGPP, x=DOC_mgL, size=LSA_sizeclass, fill=DOC_mgL/TP_ugL))+
  geom_point(shape=21, color="black")+
  scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
                                   name="Lake DOC:TP\n(mass:mass)")+
  scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
  theme_pubr(base_size = 18)+
  ylab(expression(paste('Median GPP (mg C m'^-2,' day'^-1,')')))+
  xlab(expression(paste('DOC (mg L'^-1,')')))+
      theme(legend.position = c(.90, 0.9),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0))+
    guides(size = guide_legend(label.position = "bottom", 
            title.position = "left", title.vjust = 0.8))

# MedianGPPvDOCvloadCP<-master_df %>%
#   filter(!lakeName=="Annie")%>%
#   mutate(CP=DOC_gm3/(TP_gm3*1000)) %>%
#   ggplot(aes(y=medianGPP, x=DOC_mgL, size=LSA_sizeclass, fill=CP))+
#   geom_point(shape=21, color="black")+
#   scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
#                                    name="Load DOC:TP\n(mass:mass)")+
#     scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
#   theme_classic()+
#   ylab(expression(paste('Median GPP (mg C m'^-2,' day'^-1,')')))+
#   xlab(expression(paste('DOC (mg L'^-1,')')))+
#       theme(legend.position = c(.90, 0.9),
#         legend.justification = c("right", "top"),
#         legend.box.just = "right",
#         legend.title.align = 0,
#         legend.direction = "horizontal",
#         legend.box = "vertical",
#         legend.background = element_blank(),
#         legend.margin = margin(0, 0, 0, 0),
#         legend.title = element_text(size=10))+
#     guides(size = guide_legend(label.position = "bottom", 
#             title.position = "left", title.vjust = 0.8))
# 
# MedianGPPvDOCvlakeCP<-
#   master_df %>%
#   filter(!lakeName=="Annie")%>%
#   mutate(CP=DOC_gm3/(TP_gm3*1000)) %>%
#   ggplot(aes(y=medianGPP, x=DOC_mgL, size=LSA_sizeclass, fill=DOC_mgL/TP_ugL))+
#   geom_point(shape=21, color="black")+
#   scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
#                                    name="Lake DOC:TP\n(mass:mass)")+
#   scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
#   theme_classic()+
#   ylab(expression(paste('Median GPP (mg C m'^-2,' day'^-1,')')))+
#   xlab(expression(paste('DOC (mg L'^-1,')')))+
#       theme(legend.position = c(.90, 0.9),
#         legend.justification = c("right", "top"),
#         legend.box.just = "right",
#         legend.title.align = 0,
#         legend.direction = "horizontal",
#         legend.box = "vertical",
#         legend.background = element_blank(),
#         legend.margin = margin(0, 0, 0, 0),
#         legend.title = element_text(size=10))+
#     guides(size = guide_legend(label.position = "bottom", 
#             title.position = "left", title.vjust = 0.8))



ggarrange(MeanGPPvDOCvloadCP,MeanGPPvDOCvlakeCP,
          # MedianGPPvDOCvloadCP,MedianGPPvDOCvlakeCP,
          # nrow=2,
          ncol=2,
                     labels = c("A", "B"),
                     font.label = list(size = 12, face="bold"))

# ggsave(here("results/draft MS figs/GPPversusDOC_FnOfCPandSA.png"), width=12, height=6,units="in", dpi=600)
ggsave(here("figures/SIL/GPPversusDOC_FnOfCPandSA.png"), width=12, height=6,units="in", dpi=600)



MeanGPPvDOCvloadCP
ggsave(here("figures/GLEON/GPPversusDOC_FnOfCPandSA.png"), width=12, height=6,units="in", dpi=600)

```

#### - TP vs DOC as a ftn of GPP
```{r}

#TP lake vs DOC lake
  master_df %>%
  # filter(!lakeName=="Annie")%>%
  ggplot(aes(y=TP_ugL, x=DOC_mgL, size=LSA_sizeclass, fill=log10(medianGPP)))+
  geom_point(shape=21, color="black", alpha=0.5)+
  scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
                                   name="Log GPP")+
  scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
  theme_pubr(base_size = 18)+
  ylab(expression(paste('TP (ug L'^-1,') lake conc.')))+
  xlab(expression(paste('DOC (mg L'^-1,') lake conc.')))+
      theme(legend.position = c(.90, 0.9),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0))+
    guides(size = guide_legend(label.position = "bottom", 
            title.position = "left", title.vjust = 0.8)) 


# my_breaks = c(2, 10, 50, 250, 1250, 6000)
my_breaks = c(0.1, 100, 1000)
#TP inflow vs DOC inflow
  master_df %>%
  # filter(!lakeName=="Annie")%>%
  ggplot(aes(y=(TP_mgm3), x=(DOC_gm3),
             # size=LSA_sizeclass,
             fill=medianGPP))+
  geom_point(shape=21, color="black", alpha=0.9, size=3)+
  # scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
  #                                  name="Log GPP")+
  # scale_fill_gradientn(colours = rainbow(5))+
  scale_fill_gradientn(trans = "log10", colors=rainbow(5),
                        breaks = my_breaks, labels = my_breaks,
                       name="log10 GPP")+ #Make it rainbow to match the eventual heatmap
  # scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
  theme_pubr(base_size = 10)+
  ylab(expression(paste('TP (ug L'^-1,') inflow conc')))+
  xlab(expression(paste('DOC (mg L'^-1,') inflow conc')))+
      theme(legend.position = c(.90, 0.9),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0))
    # guides(size = guide_legend(label.position = "bottom", 
    #         title.position = "left", title.vjust = 0.8))

ggsave(here("figures/CaryMeeting/TPinvsDOCin_ftnOfLSA_GPP.png"), width=4, height=4,units="in", dpi=600)


#Same as above, but loads
  master_df %>%
  filter(!lakeName=="Kentucky")%>%
  ggplot(aes(y=log10(TP_load_kg), x=log10(DOC_load_kg),
             # size=LSA_sizeclass,
             fill=medianGPP))+
  geom_point(shape=21, color="black", alpha=0.9, size=3)+
  # scale_fill_continuous_sequential(palette = "Lajolla", rev=FALSE,
  #                                  name="Log GPP")+
  # scale_fill_gradientn(colours = rainbow(5))+
  scale_fill_gradientn(trans = "log", colors=rainbow(5),
                        breaks = my_breaks, labels = my_breaks,
                       name="log10 GPP")+ #Make it rainbow to match the eventual heatmap
  # scale_size_discrete(name=expression(paste('Lake size (km'^2,')')))+
  theme_pubr(base_size = 10)+
    labs(x="DOC load (kg)",
         y="TP load (kg)")+
      theme(legend.position = c(0.4, 0.9),
        legend.justification = c("right", "bottom"),
        legend.box.just = "right",
        legend.title.align = 0,
        legend.direction = "horizontal",
        legend.box = "vertical",
        legend.background = element_blank(),
        legend.margin = margin(0, 0, 0, 0))

```


### Figure 5 - Obs vs pred
```{r}

#PREDICTED VS OBSERVED
A<-master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  filter(!dataset=='NA')%>%
  ggplot(aes(y=medianGPP, x=PPareal, fill=dataset, shape=inflows_YN))+
  geom_point(size=3, alpha=0.8)+
  theme_bw()+
  xlab(expression(paste('PRED. GPP (mg C m'^-2,' day'^-1,')')))+
  ylab(expression(paste('OBS. GPP (mg C m'^-2,' day'^-1,')')))+
  scale_fill_manual(values=c("#e63946","#457b9d"),
                    name="How were loads\ndeteremined?")+
  # scale_fill_manual(values=c("#457b9d","#457b9d"),
  #                   name="How were loads\ndeteremined?")+
  scale_shape_manual(values=c(21,25),
                     name="Does the lake\nhave surface inflow(s)?")+
  geom_text_repel(aes(label = lakeName), size = 3)+
  geom_abline(intercept = 0, slope = 1)+
  facet_grid(.~dataset)+
  theme(panel.spacing = unit(0, "lines"))+
  guides(fill = guide_legend(override.aes = list(shape = 21) ),
         shape = guide_legend(override.aes = list(fill = "black") ) )+
  xlim(c(0,10000))+ylim(c(0,10000))


#Predicted "equilibrium" DOC values are much lower than observed DOC? Why?
B<-master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  filter(!dataset=='NA')%>%  ggplot(aes(y=DOC_mgL, x=eqDOC, fill=dataset, shape=inflows_YN))+
  geom_point( size=3, alpha=0.8)+
  geom_abline(intercept = 0, slope = 1)+
  xlab(expression(paste('PRED. lake DOC mg L'^-1,)))+
  ylab(expression(paste('OBS. lake DOC mg L'^-1,)))+
  scale_fill_manual(values=c("#e63946","#457b9d"),
                    name="How were loads\ndeteremined?")+
  # scale_fill_manual(values=c("#457b9d","#457b9d"),
  #                   name="How were loads\ndeteremined?")+
  scale_shape_manual(values=c(21,25),
                     name="Does the lake\nhave surface inflow(s)?")+
    geom_text_repel(aes(label = lakeName), size = 3)+
  theme_bw()+
  facet_grid(.~dataset)+
  theme(panel.spacing = unit(0, "lines"))+
  guides(fill = guide_legend(override.aes = list(shape = 21) ),
         shape = guide_legend(override.aes = list(fill = "black") ) )+
  xlim(c(0,75))+ylim(c(0,75))


#Model tends to overpredict DOC, but it's especially bad for two lakes (EastLong, Vortsjarv)

#Relationship between equilibrium TP and actual in-lake TP
C<-master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  filter(!dataset=='NA')%>%  ggplot(aes(x=eqTP, y=TP_ugL, fill=dataset, shape=inflows_YN))+
  geom_point(size=3, alpha=0.8)+
  geom_abline(intercept = 0, slope = 1)+
  xlab(expression(paste('PRED. lake TP ug L'^-1,)))+
  ylab(expression(paste('OBS. lake TP ug L'^-1,)))+
  scale_fill_manual(values=c("#e63946","#457b9d"),
                    name="How were loads\ndeteremined?")+
  # scale_fill_manual(values=c("#457b9d","#457b9d"),
  #                   name="How were loads\ndeteremined?")+
  scale_shape_manual(values=c(21,25),
                     name="Does the lake\nhave surface inflow(s)?")+
  theme_bw()+
  geom_text_repel(aes(label = lakeName), size = 3)+
  facet_grid(.~dataset)+
  theme(panel.spacing = unit(0, "lines"))+
  guides(fill = guide_legend(override.aes = list(shape = 21) ),
         shape = guide_legend(override.aes = list(fill = "black") ) )+
  xlim(c(0,350))+ylim(c(0,350))



#What do the zMix estimates look like compared to actual mean zMix observed values?
D<-master_df %>%
  left_join(., preds_full,  by="lakeName") %>%
    left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  filter(!dataset=='NA')%>%  ggplot(aes(y=meanzMix, x=zMix_mod, fill=dataset, shape=inflows_YN))+
  geom_point(size=3, alpha=0.8)+
  geom_abline(intercept = 0, slope = 1)+
  scale_fill_manual(values=c("#e63946","#457b9d"),
                    name="How were loads\ndeteremined?")+
  # scale_fill_manual(values=c("#457b9d","#457b9d"),
  #                   name="How were loads\ndeteremined?")+
  scale_shape_manual(values=c(21,25),
                     name="Does the lake\nhave surface inflow(s)?")+
  xlab("PRED. zMix (m)")+
  ylab("OBS. zMix (m)")+
  theme_bw()+
  geom_text_repel(aes(label = lakeName), size = 3)+
  facet_grid(.~dataset)+
  theme(panel.spacing = unit(0, "lines"))+
  guides(fill = guide_legend(override.aes = list(shape = 21) ),
         shape = guide_legend(override.aes = list(fill = "black") ) )+
  xlim(c(0,10))+ylim(c(0,10))


(A+B)/(C+D)+
  plot_layout(guides = 'collect')+
  plot_annotation(tag_levels = 'A')
ggsave(here("results/draft MS figs/Fig5.predVSmeasuredGPP-DOC-TP-zMix.png"), width=9, height=6,units="in", dpi=600)


```


### SUPP FIGS

#### Figure S1. Maps

```{r}


metadata$inflows_YN <- factor(metadata$inflows_YN, levels = c("yes", "no"), 
                  labels = c("Lakes with surface inflows", "Lakes without surface inflows"))

length(unique(metadata$Country))

GPP_distribution<-bella_metab_summary %>% 
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  # mutate(inflows_YN= factor(inflows_YN,
  #                           levels=c("yes","no")))%>%
  # ggplot(aes(x=reorder(lakeName, meanGPP, FUN=mean), y=meanGPP, fill=inflows_YN))+
  ggplot(aes(x=reorder(lakeName, meanGPP, FUN=mean), y=GPP50, label=lakeName))+
  geom_point(shape=21,size=3)+
  # geom_point(aes(y=GPP50, x=lakeName))+
  geom_boxplot(aes(ymin = GPP5,
                   lower = GPP25,
                   middle = GPP50,
                   upper = GPP75,
                   ymax = GPP95),
               stat='identity')+
  ylab(expression(paste('GPP (mg C m'^-2,' day'^-1,')')))+
  # facet_wrap(.~inflows_YN, scales="free")+
  # theme_pubr(base_size=18)+
  theme_few()+
  # scale_fill_manual(values=c("#52b788","#FFFFFF"))+
  theme(
        legend.position="none",
        axis.title.y=element_text(size=24),
        axis.text.y=element_text(size=24),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())+
    scale_y_log10()+
  geom_text_repel(
    # force_pull   = 0, # do not pull toward data points
    # nudge_y      = 0.05,
    # direction    = "x",
    # # angle        = 45,
    # hjust        = 1,
    # segment.size = 0.2,
    # max.iter = 1e4,
    # max.time = 1,
    max.overlaps = 15,
    size        = 8,
    box.padding = 2
  ) 
    # geom_label_repel() 
GPP_distribution

ggsave(here("figures/GLEON/GPP_dist.png"), width=11, height=8,units="in", dpi=600)

world <- ne_countries(scale = "medium", returnclass = "sf")
library(maps)
world1 <- sf::st_as_sf(map('world', plot = FALSE, fill = TRUE))


# generate world map
GLEON_global_map_alt<-ggplot(data = world) +
  geom_sf() +
  # coord_sf(xlim= c(-120,NA), ylim = c(-50, NA)) +
  labs( x = "Longitude", y = "Latitude") +
  # ggtitle("Global distribution of lakes for Kelly model test ")+
  geom_jitter(data=master_df %>%
              left_join(., metadata %>%
                    select(lakeName, inflows_YN,`Longitude (decimal degrees)`,
                           `Latitude (decimal degrees)`), by="lakeName") ,
             aes(x=`Longitude (decimal degrees)`,
                 y=`Latitude (decimal degrees)`,
                 fill=inflows_YN),
             shape=21, color="black", size=2, fill="#ffba08")+
    # scale_fill_manual(values=c("#52b788","#FFFFFF"))+
  theme_pubr(base_size=18)+
        theme(
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill="#98dbfa"),
        panel.background = element_rect(fill="#98dbfa")
      )
GLEON_global_map_alt
  # ggsave(here("figures/SIL/global_map.png"), width=10, height=9,units="in", dpi=600)


#Morphometry density plots or histograms


#density plot
my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", LSA_km2="log[10]~Surface~Area~(km^2)",
                             zMean="log[10]~Mean~depth~(m)", V_m3="log[10]~Volume~(m^3)"),
                           default = label_parsed)

density_plot<-master_df %>%
  select(HRT_days, LSA_km2, zMean, V_m3) %>%
  pivot_longer(1:4)%>%
  # mutate(name= factor(name, labels=c(expression('hi'[5]*'there'[6]^8*'you'[2]),
  #                                    "beta",
  #                                    "gamma",
  #                                    "poop")))%>%
  ggplot()+
  geom_density(aes(x = log10(value), fill=name)) +
  geom_rug(aes(x = log10(value), y = 0), sides="b")+
  facet_wrap(~name, nrow=2, scales="free",
             labeller=my_labeller, strip.position="bottom")+
  scale_fill_manual(values=c("#5f0f40","#9a031e","#fb8b24","#e36414"))+
  # theme_minimal()+
  theme_pubr(base_size = 18)+
  theme(legend.position="none",
        axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )+
  ylab("Density")
 density_plot
 
 ##ASSEMBLE
 top<-(GLEON_global_map_alt | density_plot )
 Fig1<-((GLEON_global_map_alt | density_plot ) / GPP_distribution ) +
   plot_layout(heights = c(1, 1.8))+
   plot_annotation(tag_levels = 'A')
  Fig1
  
  ggsave(here("results/draft MS figs/studyMapAndDistributions.png"), width=10, height=9,units="in", dpi=600)

```

##### SIL maps & violin plots
```{r}

north_america <- ne_countries(continent = "north america",scale = "medium", returnclass = "sf")

GLEON_NA<-ggplot(data = north_america) +
  geom_sf() +
  coord_sf(xlim= c(-125,-60), ylim = c(25, 48)) +
  labs( x = "Longitude", y = "Latitude") +
  # geom_sf_label(aes(label = continent))+
  geom_jitter(data=master_df %>%
              left_join(., metadata %>%
                    select(lakeName, Country,inflows_YN,`Longitude (decimal degrees)`,
                           `Latitude (decimal degrees)`), by="lakeName") %>%
                filter(Country %in% c("USA","Canada")),
             aes(x=`Longitude (decimal degrees)`,
                 y=`Latitude (decimal degrees)`),
             shape=21, color="black", size=4,  fill="#ffba08", alpha=0.5)+

  theme_pubr(base_size=18)+
        theme(
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill="#FFFFFF"),
        panel.background = element_rect(fill="#FFFFFF")
      )+
      ggspatial::annotation_scale(
    location = "br",
    bar_cols = c("grey60", "white")
  ) +
  ggspatial::annotation_north_arrow(
    location = "br", which_north = "true",
    pad_x = unit(0.4, "in"), pad_y = unit(0.4, "in"),
    style = ggspatial::north_arrow_nautical(
      fill = c("grey40", "white"),
      line_col = "grey20"
    )
  )
GLEON_NA
  ggsave(here("figures/CaryMeeting/north_american_sites.png"), width=10, height=9,units="in", dpi=600)

  
 europe <- ne_countries(continent = "europe",scale = "medium", returnclass = "sf")
 
  GLEON_EURO<-ggplot(data = europe) +
  geom_sf() +
  coord_sf(xlim= c(-10,25), ylim = c(50, 70)) +
  labs( x = "Longitude", y = "Latitude") +
  # geom_sf_label(aes(label = continent))+
  geom_jitter(data=master_df %>%
              left_join(., metadata %>%
                    select(lakeName, Country,inflows_YN,`Longitude (decimal degrees)`,
                           `Latitude (decimal degrees)`), by="lakeName") %>%
                filter(!Country %in% c("USA","Canada","New Zealand","Taiwan","China")),
             aes(x=`Longitude (decimal degrees)`,
                 y=`Latitude (decimal degrees)`),
             shape=21, color="black", size=4,  fill="#ffba08", alpha=0.5)+

  theme_pubr(base_size=18)+
        theme(
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill="#FFFFFF"),
        panel.background = element_rect(fill="#FFFFFF")
      )+
      ggspatial::annotation_scale(
    location = "tl",
    bar_cols = c("grey60", "white")
  ) +
  ggspatial::annotation_north_arrow(
    location = "tl", which_north = "true",
    pad_x = unit(0.4, "in"), pad_y = unit(0.4, "in"),
    style = ggspatial::north_arrow_nautical(
      fill = c("grey40", "white"),
      line_col = "grey20"
    )
  )
GLEON_EURO
  ggsave(here("figures/CaryMeeting/european_sites.png"), width=10, height=9,units="in", dpi=600)



world <- ne_countries(scale = "medium", returnclass = "sf")
library(spData)
data("us_states", package = "spData")
# us_states_2163 = st_transform(us_states, crs = 2163)
us_states_bb = st_as_sfc(st_bbox(us_states))

data("world", package = "spData")
europe <- world %>% filter(continent %in% c("Europe")) %>% filter(name_long %in% metadata$Country)
europe_bb = st_as_sfc(st_bbox(europe))
NZ <- world %>% filter(name_long=="New Zealand")
NZ_bb = st_as_sfc(st_bbox(NZ))
asia_subset <- world %>% filter(name_long %in% c("China","Taiwan"))
asia_subset_bb = st_as_sfc(st_bbox(asia_subset))


# generate world map
GLEON_global_map_alt<-ggplot(data = world) +
  geom_sf() +
  geom_sf(data = us_states_bb, fill = NA, color = "black", size = 1) +
  geom_sf(data = europe_bb, fill = NA, color = "black", size = 1) +
    geom_sf(data = NZ_bb, fill = NA, color = "black", size = 1) +
  # coord_sf(xlim= c(-120,NA), ylim = c(-50, NA)) +
  labs( x = "Longitude", y = "Latitude") +
  # ggtitle("Global distribution of lakes for Kelly model test ")+
  geom_jitter(data=master_df %>%
              left_join(., metadata %>%
                    select(lakeName, inflows_YN,`Longitude (decimal degrees)`,
                           `Latitude (decimal degrees)`), by="lakeName") ,
             aes(x=`Longitude (decimal degrees)`,
                 y=`Latitude (decimal degrees)`,
                 fill=inflows_YN),
             shape=21, color="black", size=2, fill="#ffba08")+
    # scale_fill_manual(values=c("#52b788","#FFFFFF"))+
  theme_pubr(base_size=18)+
        theme(
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill="#FFFFFF"),
        panel.background = element_rect(fill="#FFFFFF")
      )
GLEON_global_map_alt
ggsave(here("figures/CaryMeeting/GlobalMap.png"), width=12, height=4,units="in", dpi=600)

  GLEON_NZ<-ggplot(data = NZ) +
  geom_sf() +
  # coord_sf(xlim= c(-10,25), ylim = c(50, 70)) +
  labs( x = "Longitude", y = "Latitude") +
  # geom_sf_label(aes(label = continent))+
  geom_jitter(data=master_df %>%
              left_join(., metadata %>%
                    select(lakeName, Country,inflows_YN,`Longitude (decimal degrees)`,
                           `Latitude (decimal degrees)`), by="lakeName") %>%
                filter(Country %in% c("New Zealand")),
             aes(x=`Longitude (decimal degrees)`,
                 y=`Latitude (decimal degrees)`),
             shape=21, color="black", size=4,  fill="#ffba08", alpha=0.5)+

  theme_pubr(base_size=18)+
        theme(
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill="#FFFFFF"),
        panel.background = element_rect(fill="#FFFFFF")
      )+
      ggspatial::annotation_scale(
    location = "tl",
    bar_cols = c("grey60", "white")
  ) +
  ggspatial::annotation_north_arrow(
    location = "tl", which_north = "true",
    pad_x = unit(0.4, "in"), pad_y = unit(0.4, "in"),
    style = ggspatial::north_arrow_nautical(
      fill = c("grey40", "white"),
      line_col = "grey20"
    )
  )
GLEON_NZ
ggsave(here("figures/CaryMeeting/NZMap.png"), width=4, height=4,units="in", dpi=600)

  GLEON_ASIA<-ggplot(data = asia_subset) +
  geom_sf() +
  # coord_sf(xlim= c(-10,25), ylim = c(50, 70)) +
  labs( x = "Longitude", y = "Latitude") +
  # geom_sf_label(aes(label = continent))+
  geom_jitter(data=master_df %>%
              left_join(., metadata %>%
                    select(lakeName, Country,inflows_YN,`Longitude (decimal degrees)`,
                           `Latitude (decimal degrees)`), by="lakeName") %>%
                filter(Country %in% c("China","Taiwan")),
             aes(x=`Longitude (decimal degrees)`,
                 y=`Latitude (decimal degrees)`),
             shape=21, color="black", size=4,  fill="#ffba08", alpha=0.5)+

  theme_pubr(base_size=18)+
        theme(
        axis.line = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        plot.background = element_rect(fill="#FFFFFF"),
        panel.background = element_rect(fill="#FFFFFF")
      )+
      ggspatial::annotation_scale(
    location = "tl",
    bar_cols = c("grey60", "white")
  ) +
  ggspatial::annotation_north_arrow(
    location = "tl", which_north = "true",
    pad_x = unit(0.4, "in"), pad_y = unit(0.4, "in"),
    style = ggspatial::north_arrow_nautical(
      fill = c("grey40", "white"),
      line_col = "grey20"
    )
  )
GLEON_ASIA
ggsave(here("figures/CaryMeeting/AsiaMap.png"), width=4, height=4,units="in", dpi=600)

bella_metab_summary %>% 
  left_join(., metadata %>%
              select(lakeName, inflows_YN), by="lakeName") %>%
  ggplot(aes(x=reorder(lakeName, meanGPP, FUN=mean), y=medianGPP))+
  geom_boxplot(aes(ymin = GPP5,
                   lower = GPP25,
                   middle = GPP50,
                   upper = GPP75,
                   ymax = GPP95),
               stat='identity')+
  ylab(expression(paste('GPP (mg C m'^-2,' day'^-1,')')))+
  theme_pubr(base_size=14)+
  theme(
        legend.position="none",
        axis.title.x=element_blank(),
        axis.text.x=element_text(angle = 45, hjust = 1, size=12))+
    scale_y_log10()
# ggsave(here("figures/SIL/GPP_boxplots.png"), width=12, height=4,units="in", dpi=600)



bella_metab_extendedSummer_withMetaData %>%
  filter(GPP_mgCm2>1) %>%
  group_by(lakeName) %>%
  arrange(desc(GPP_mgCm2)) %>%
  slice(1:20) %>%
  inner_join(master_df %>% select(meanGPP, lakeName)) %>%
  ggplot(aes(x=reorder(lakeName, meanGPP, FUN=mean), y=log10(GPP_mgCm2)))+
  geom_violin()+
  ylab(expression(paste('GPP (mg C m'^-2,' day'^-1,')')))+
  theme_pubr(base_size=14)+
  theme(
        legend.position="none",
        axis.title.x=element_blank(),
        axis.text.x=element_text(angle = 45, hjust = 1, size=12))+
    scale_y_log10()


#density plot
my_labeller <- as_labeller(c(HRT_days="log[10]~HRT~(days)", SA_ha="log[10]~Surface~Area~(ha)",
                             zMean="log[10]~Mean~depth~(m)", V_m3="log[10]~Volume~(m^3)"),
                           default = label_parsed)

density_plot<-master_df %>%
  select(HRT_days, SA_ha, zMean, V_m3) %>%
  pivot_longer(1:4)%>%
  # mutate(name= factor(name, labels=c(expression('hi'[5]*'there'[6]^8*'you'[2]),
  #                                    "beta",
  #                                    "gamma",
  #                                    "poop")))%>%
  ggplot()+
  geom_density(aes(x = log10(value)),fill="#5E813F") +
  geom_rug(aes(x = log10(value), y = 0), sides="b")+
  facet_wrap(~name, nrow=1, scales="free",
             labeller=my_labeller, strip.position="bottom")+
  # geom_vline(data=master_df %>%
  #              select(HRT_days, SA_ha, zMean, V_m3) %>%
  #              pivot_longer(1:4) %>% group_by(name) %>% 
  #              summarise(value=median(value, na.rm=TRUE))),
  # aes(xintercept=value,
  #           color="blue", linetype="dashed", size=1)+
  theme_pubr(base_size = 18)+
  theme(legend.position="none",
        axis.title.x=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )+
  ylab("Density")


 density_plot
 ggsave(here("figures/SIL/morphometry_distributions.png"), width=14, height=4,units="in", dpi=600)

 
 
my_labeller_x <- as_labeller(c(HRT="log[10]~(days)", `Surface area`="log[10]~(ha)",
                             `Mean depth`="log[10]~(m)", Volume="log[10]~(m^3)"),
                           default = label_parsed)

 master_df %>%
  select(HRT_days, SA_ha, zMean, V_m3) %>%
  pivot_longer(1:4) %>%
  mutate(name=factor(name,
                     levels=c("HRT_days","SA_ha","V_m3","zMean"),
                     labels=c("HRT","Surface area","Volume","Mean depth"))) %>%
  ggplot(aes(x=log10(value), y=name)) +
  stat_density_ridges(quantile_lines = TRUE, quantiles = 2, fill="grey80") +
  facet_wrap(~name, nrow=4, scales="free",
             labeller=my_labeller_x, strip.position="bottom")+
  geom_text(data=master_df %>%
  select(HRT_days, SA_ha, zMean, V_m3) %>%
  pivot_longer(1:4) %>%
  mutate(name=factor(name,
                     levels=c("HRT_days","SA_ha","V_m3","zMean"),
                     labels=c("HRT","Surface area","Volume","Mean depth"))) %>%
    group_by(name) %>% 
              summarise(value=median(value)),
            aes(label=sprintf("%1.1f", round(value,0))), 
            position=position_nudge(y=-0.1), colour="red", size=3.5)+
  geom_rug(aes(x = log10(value), y = 0), sides="b")+
  theme_pubr(base_size = 18)+
  theme(legend.position="none",
        axis.title.y=element_blank(),
        # axis.text.y=element_blank(),
        axis.title.x=element_blank(),
        axis.ticks.y=element_blank(),
        strip.placement = "outside",
        strip.background = element_blank(),
        # strip.text = element_text(size=12),
        # axis.text.y= element_text(size=12),
        )
 ggsave(here("figures/SIL/morphometry_distributions.png"), width=4, height=10,units="in", dpi=600)

```


#### Figure S2. Daily metab
```{r, out.width = '100%',fig.height=15}
bella_metab_extendedSummer_withMetaData  <- bella_metab_extendedSummer %>%
  mutate(GPP_mgCm2 = na_if(GPP_mgCm2, GPP_mgCm2<1)) %>%
  left_join(., metadata, by = c('lakeName'))

bella_metab_withMetaData_extendedSummer <- bind_rows(bella_metab_withMetaData_northern_extendedSummer, bella_metab_withMetaData_southern_extendedSummer, YYL)


bella_metab_extendedSummer_withMetaData %>%
  group_by(lakeName)%>%
  mutate(n=n(),
         GPP_mgCm2 = na_if(GPP_mgCm2, GPP_mgCm2<1),
         n_NAs=sum(is.na(GPP_mgCm2)),
         perc_missing_days=(n_NAs/153)*100) %>%
    filter(!perc_missing_days>50)%>%
  # filter(hemisphere=="northern")%>%
  # ggplot(aes(x=solarDay,y=GPP_mgCm2, fill=season))+
    ggplot(aes(x=solarDay,y=GPP_mgCm2))+
  geom_point(size=1.5, shape=21, fill="grey50", alpha=0.5)+
  # scale_fill_manual(values=c("white","forestgreen"),
  #                   
  #                   labels=c("excluded","included"))+
    ylab(expression(paste('GPP (mg O2 m'^-2,' day'^-1,')')))+
  theme_few()+
  facet_wrap(.~lakeName, scales="free", ncol=7)+
  scale_x_date(date_breaks = "2 months", date_labels = "%m-%d",  breaks = breaks_pretty(3)) 



ggsave(here("figures/CaryMeeting/SUPP.dailyGPPincluded.png"), width=14, height=14,units="in", dpi=300)


```


#### Figure S2. Measured vs. modeled loads

```{r, out.width = '100%',fig.height=15}


modelled_loads_kg_comparison <- modelled_loads_kg %>%
  rename(TPinflow_modelled_mgm3=TP_mgm3,
         DOCinflow_modelled_gm3=DOC_gm3,
         Qin_modelled_m3day=Qin,
         TP_load_kg_modelled=TP_load_kg,
         DOC_load_kg_modelled=DOC_load_kg) %>%
  select(-dataset)

inflow_conc_comparison <- inflow_conc_summary %>%
  filter(dataset=="measured") %>%
  rename(DOC_load_kg_measured=DOC_load,
         TP_load_kg_measured=TP_load,
         Qin_m3sec=Qin,
         TPinflow_measured_mgm3=TP_mgm3,
         DOCinflow_measured_gm3=DOC_gm3) %>%
  mutate(Qin_m3day=Qin_m3sec*86400,
         DOC_load_kg_measured=DOC_load_kg_measured/n_days/1000,
         TP_load_kg_measured=TP_load_kg_measured/n_days/1000000) %>%
  select(-Qin_m3sec,-dataset)
         
         
         
inflow_comparison <- left_join(inflow_conc_comparison,modelled_loads_kg_comparison, by=c("lakeName")) %>%
    mutate(
    DOCinflow_measured_gm3 = replace(DOCinflow_measured_gm3, lakeName=="EastLong", 35.2), #replace with values from gridSearchInput file
    TPinflow_measured_mgm3 = replace(TPinflow_measured_mgm3, lakeName=="EastLong", 48.9)) %>%
  #calculate the C:P
  mutate(DOC_TP_measured=DOCinflow_measured_gm3/TPinflow_measured_mgm3,
         DOC_TP_modeled=DOCinflow_modelled_gm3/TPinflow_modelled_mgm3)

# A<-inflow_comparison %>%
#   ggplot(aes(x=(DOC_load_kg_measured),y=(DOC_load_kg_modelled))) +
#   geom_point()+
#   geom_abline(intercept=0, slope=1)+
#   theme_few()+
#   geom_text_repel(aes(label = lakeName), size = 3, max.overlaps=2)+
#   labs(x=" measured DOC load (kg/day)",
#        y=" modeled DOC load (kg/day)")

B<-inflow_comparison %>%
  ggplot(aes(x=(DOCinflow_measured_gm3),y=(DOCinflow_modelled_gm3))) +
  geom_point()+
  geom_abline(intercept=0, slope=1)+
  theme_few()+
  # geom_text_repel(aes(label = lakeName), size = 3, max.overlaps=2)+
  labs(x=expression(paste('Measured inflow DOC g m'^-3,)),
       y=expression(paste('Modeled inflow DOC g m'^-3,)))


# C<-inflow_comparison %>%
#   ggplot(aes(x=(TP_load_kg_measured),y=(TP_load_kg_modelled))) +
#   geom_point()+
#   geom_abline(intercept=0, slope=1)+
#   theme_few()+
#   geom_text_repel(aes(label = lakeName), size = 3, max.overlaps=2)+
#   labs(x=" measured TP load (kg/day)",
#        y=" modeled TP load (kg/day)")

D<-inflow_comparison %>%
  ggplot(aes(x=(TPinflow_measured_mgm3),y=(TPinflow_modelled_mgm3))) +
  geom_point()+
  geom_abline(intercept=0, slope=1)+
  theme_few()+
  # geom_text_repel(aes(label = lakeName), size = 3, max.overlaps=2)+
  labs(x=expression(paste('Measured inflow TP mg m'^-3,)),
       y=expression(paste('Modeled inflow TP mg m'^-3,)))


gg_title = str_wrap("Modeled vs. measured TP and DOC inflow concentrations", width=100)
 
# (A+B)/(C+D) + plot_annotation(title = gg_title)
(B+D) 
# + plot_annotation(title = gg_title)
  

ggsave(here("figures/modeled_vs_measured_loads_18lakes.png"), dpi=600, width=8,height=5, units="in")


#Plot it on the log scale
# A<-inflow_comparison %>%
#   ggplot(aes(x=log10(DOC_load_kg_measured),y=log10(DOC_load_kg_modelled))) +
#   geom_point()+
#   geom_abline(intercept=0, slope=1)+
#   theme_few()+
#   labs(x="log10 measured DOC load (kg/day)",
#        y="log10 modeled DOC load (kg/day)")

B<-inflow_comparison %>%
  ggplot(aes(x=log10(DOCinflow_measured_gm3),y=log10(DOCinflow_modelled_gm3))) +
  geom_point()+
  geom_abline(intercept=0, slope=1)+
  theme_few()+
  labs(x=expression(paste('log10 Measured inflow DOC g m'^-3,)),
       y=expression(paste('log10 Modeled inflow DOC g m'^-3,)))

# C<-inflow_comparison %>%
#   ggplot(aes(x=log10(TP_load_kg_measured),y=log10(TP_load_kg_modelled))) +
#   geom_point()+
#   geom_abline(intercept=0, slope=1)+
#   theme_few()+
#   labs(x="log10 measured TP load (kg/day)",
#        y="log10 modeled TP load (kg/day)")

D<-inflow_comparison %>%
  ggplot(aes(x=log10(TPinflow_measured_mgm3),y=log10(TPinflow_modelled_mgm3))) +
  geom_point()+
  geom_abline(intercept=0, slope=1)+
  theme_few()+
  labs(x=expression(paste('log10 Measured inflow TP mg m'^-3,)),
       y=expression(paste('log10 Modeled inflow TP mg m'^-3,)))

gg_title = str_wrap("Modeled vs. measured TP and DOC loads and inflow concentrations", width=100)
 
# (A+B)/(C+D) + plot_annotation(title = gg_title)
B+D

lm1<- lm(log10(TPinflow_modelled_mgm3)~log10(TPinflow_measured_mgm3), data=inflow_comparison)
summary(lm1)

ggsave(here("figures/modeled_vs_measured_loads_18lakes_log10.png"), dpi=600, width=8,height=5, units="in")



#Compare the C:P
gg_title = str_wrap("modeled values are from preliminary Metropolis Results (wide range)", width=40)
 

E<-inflow_comparison %>%
  ggplot(aes(x=DOC_TP_measured,y=DOC_TP_modeled)) +
  geom_point()+
  geom_abline(intercept=0, slope=1)+
  theme_few()+
  geom_text_repel(aes(label = lakeName), size = 3, max.overlaps=2)+
  labs(x="Measured DOC:TP",
       y="Modeled DOC:TP")
E + plot_annotation(title = gg_title)
ggsave(here("figures/modeled_vs_measured_CtoP_18lakes.png"), dpi=600, width=5,height=5, units="in")

```
